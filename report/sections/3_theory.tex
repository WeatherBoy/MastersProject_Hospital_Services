\section{Theory}
Of the three main tasks explored in this thesis, developing a \textit{scheduling assistance tool}, which we henceforth will refer to as '\textit{the scheduling task}', required the most mathematical approach. \textit{The scheduling task} is a case of the \textbf{Generalised Assignment Problem}\cite{Wiki-general-assignment-prob}, which can ultimately be expressed as a \textbf{Linear Program}\cite{Wiki-linear-programming}, specifically, a \textbf{Binary Integer Program}.
The following sections explore different theoretical approaches that might yield a satisfactory solution to such a \textbf{Generalised Assignment Problem}.

\subsection{Genetic Algorithms (GAs)}
A Genetic Algorithm, as first introduced by John Holland\cite{Genetic-Algorithm-original} in 1975\footnote{Though later revised in 1992.}, is a metaheuristic within primarily \textbf{Computer Science} and \textbf{Operations Research} (OR). Inspired by evolutionary theory's natural selection, a GA is typically employed for \textbf{Optimisation} and \textbf{Search problems}.
\\
In short, inspired by natural selection, a GA scheme initiates, at random, a pool of \textit{candidate solutions} called the \textit{initial generation}. It then evaluates the solutions with respect to the given domain and assigns each of them a \textit{fitness score}. Finally, it pairs the solutions with the best fitness, creating a new set of candidate solutions called the \textit{next generation}. However, in order to avoid converging towards some \textit{local optimum}, a bit of stochasticity (\textit{mutation}) is introduced in each generation. The GA scheme then iterates this entire process, stopping when reaching some criteria, either time or a threshold on the fitness score.
\\
\\
A Genetic Algorithm, boiled down to its base parts, consists of an objective function $f : \mathbb{R}^N \rightarrow [0,1]$, for some $N \in \mathbb{N}_0$, a \textit{selection criteria}, and a population of \textit{phenotypes}, the candidate solutions - each with its own \textit{genotype}. They are domain-dependent but are frequently represented as an $N$-dimensional vector. The genotypes will often be the actions or set of rules from which the phenotype can be derived. However, this is also largely dependent on the domain. For some problems, the genotype and phenotype are simply identical.
\\
Finally, the objective function $f$ and selection criteria are largely the crux of the GA scheme. While the phenotypes and their respective genotypes, are essentially bound to the domain, the objective function and selection criteria can be modelled for better results. The objective function and selection criteria could be considered the Genetic Algorithm's counterpart to Machine Learning's (ML) hyperparameters.
\\
The objective function $f$, evaluates to a scalar, usually standardised to the real interval $[0,1]$, hence $f$ doesn't need to be differentiable nor even continuous. This feature can allow for some creative objective functions specifically suited to the given problem.
\\
The selection criteria is how we pick the parents for the next generations. The parents, a set of two phenotypes, always produce two children to keep the population size constant throughout the iterations of the GA scheme. However, picking the parents can be a science in itself. Detailed below are some different algorithms used to perform the selection step.

\subsubsection{Selection Algorithms}
