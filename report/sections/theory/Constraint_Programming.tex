\subsection{Constraint Programming}
Another approach for solving the \textit{scheduling task} is Constraint Programming (CP)\footnote{Constraint Programming is a somewhat odd nomenclature, as \textit{programming} here refers to 'the process of scheduling' rather than in the sense of a computer programming language.}. CP is concerned with problems that require a feasible solution. Often, this involves searching for a "needle within a haystack", as CP aims to arrive at a solution satisfying a complex set of constraints. As such, contrary to the GA scheme, CP isn't inherently an optimisation technique and won't even necessarily use an objective function.
\\
As we will argue later, the domain posed by the \textit{scheduling task} gives way to a subfield of CP called satisfiability (SAT). Satisfiability concerns checking whether a boolean formula holds (is satisfiable) under some truth assignment to its variables. SAT solvers are explicitly made for solving such problems, so in the following sections, we will elaborate on different algorithms employed by such solvers.

\subsubsection{Conjunctive Normal Form}\label{sec:CNF}
However, although not inherent to boolean satisfiability, most SAT solvers work on boolean formulas in Conjunctive Normal Form (CNF). Therefore, we will first introduce CNF.
\\
From Ben-Ari (chapter 4)\cite{Math-Logic-for-CompSci} we have the following definition:
\begin{definition}\label{def:CNF}
    A formula is in conjunctive normal form (CNF) if and only if it is a conjunction of disjunctions of literals.
\end{definition}
Here, conjunction and disjunction refer to the logical connectives (boolean operators) $\wedge$ and $\vee$, respectively. While a formula and a literal, as given by Ben-Ari (chapter 2)\cite{Math-Logic-for-CompSci}, can be formally defined as:
\begin{definition}\label{def:propositional_formulas}
    A formula in propositional logic is a tree defined recursively:
    \begin{itemize}
        \item A formula is a leaf labeled by an atomic proposition (often shortened
        to atoms).
        \item A formula is a node labeled by $\neg$ with a single child that is a formula.
        \item A formula is a node labeled by one of the boolean operators with two children both of which are formulas.
    \end{itemize}
\end{definition}
\begin{definition}\label{def:propositional_atoms}
    A literal is an atom or the negation of an atom. An atom is a positive
    literal and the negation of an atom is a negative literal. For any atom $p$, $\{p,\neg p\}$ is a complementary pair of literals.
    \\
    For any formula $A$, $\{A,\neg A\}$ is a complementary pair of formulas. $A$ is the complement of $\neg A$ and $\neg A$ is the complement of $A$.
\end{definition}
We will now briefly discuss how to arrive at CNF.

\paragraph{Propositional logic to Conjunctive Normal Form}
Ben-Ari (chapter 4)\cite{Math-Logic-for-CompSci} gives us the following theorem:
\begin{theorem}
    Every formula in propositional logic can be transformed into an equivalent formula in CNF.
\end{theorem}
Which is accompanied by a somewhat unintuitive and seemingly inadequate proof; however, it can be boiled down to the following: using \textbf{def} \ref{def:propositional_formulas}, if we can convert every formula of another boolean operator into a logically equivalent formula using only conjunctions and disjunctions, then it is simply a question of propagating negations inwards and whether we can redistribute the conjunctions and disjunctions. We can understand this as: It is necessary but not satisfactory that all boolean operators are either disjunctions or conjunctions. This is an example of a formula, for $A$, $B$ being atoms as per \textbf{def} \ref{def:propositional_atoms}, of only conjunctions and disjunctions which aren't in CNF
\begin{equation*}
    A \vee (B \wedge C).
\end{equation*}
And as per the final part of \textbf{def} \ref{def:CNF}, the negation boolean operator must apply solely to an atom, making it a literal. Hence, it is necessary to propagate negations inwards (to the atomic level).
\begin{enumerate}
    \item Converting all boolean operators to disjunctions and conjunctions by logical equivalent\footnote{We will let the reader verify for themselves, that these are in fact equivalent.} formulas:
    \begin{align*}
        A \leftrightarrow B &\equiv (A \rightarrow  B) \wedge (B \rightarrow A) \qquad &\text{biimplication},
        \\
        A \oplus B &\equiv \neg (A \rightarrow B) \vee \neg (B \rightarrow A) \qquad &\text{exclusive or/ logical XOR},
        \\
        A \rightarrow B &\equiv \neg A \vee B \qquad &\text{implication},
        \\
        A \uparrow B &\equiv \neg (A \wedge B) \qquad &\text{non-conjunction/ logical NAND},
        \\
        A \downarrow B &\equiv \neg (A \vee B) \qquad &\text{non-disjunction/ logical NOR}.
    \end{align*}
    \item Propagate negations inward with De Morgan's laws\cite{A-Concise-Introduction-to-Logic,Introduction-to-logic,Math-Logic-for-CompSci}:
    \begin{align*}
        \neg (A \wedge B) &\equiv (\neg A \vee \neg B),
        \\
        \neg (A \vee B) &\equiv (\neg A \wedge \neg B).
    \end{align*}
    \item Remove any redundant double negations, which may arise from the previous two steps:
    \begin{equation*}
        \neg \neg A \equiv A.
    \end{equation*}
    \item Finally, we can make the formula a conjunction of disjunctions by utilising the distributive property of boolean operators:
    \begin{align*}
        A \vee (B \wedge C) &\equiv (A \vee B) \wedge (A \vee C),
        \\
        (A \wedge B) \vee C &\equiv (A \vee C) \wedge (B \vee C).
    \end{align*}
\end{enumerate}
In appendix \autoref{sec:CNF_conversion_Examp}, we give an example of CNF conversion, going from
\begin{equation*}
    \Big(
        p_1 \leftrightarrow (
            p_2 \vee \neg p_3
        )
    \Big) \wedge \Big(
        p_5 \rightarrow (
            p_1 \uparrow p_4
        )
    \Big) \wedge \Big(
        p_4 \oplus p_2
    \Big),
\end{equation*}
to
\begin{equation*}
    (
        \neg p_1 \vee p_2 \vee \neg p_3
    ) \wedge (
        p_1 \vee \neg p_2 
    ) \wedge (
        p_1 \vee p_3
    ) \wedge (
        \neg p_5 \vee \neg p_1 \vee \neg p_4
    ) \wedge (
        p_2 \vee p_4
    ) \wedge (
        \neg p_2 \vee \neg p_4
    ).
\end{equation*}


\subsubsection{DPLL}
The DPLL algorithm, introduced by Davis, Logemann, and Loveland in 1961~\cite{Original-DPLL-Article}, is a refinement over Davis' and Putnam's (DP) algorithm~\cite{Original-DP-Article} from the year prior. Many modern SAT solvers build off the foundation laid by the DPLL algorithm; as such, it makes for a good introduction.
\\
\\
Conceptually, DPLL inherits from the backtracking paradigm~\cite{Wiki-backtracking}. Like other backtracking algorithms, it aims to avoid exhaustive search by immediately abandoning  'candidate solutions' that do not yield a feasible solution. However, unlike naive backtracking, DPLL includes additional deduction mechanisms, most notably \emph{unit propagation} and \emph{pure literal elimination}, that prune the search space more aggressively.
\\
As previously mentioned, the SAT problem, at its base, concerns checking whether there exists a truth assignment (valuation) \(\mathcal{A}\) such that a given Boolean formula \(\Phi\), expressed in CNF, is satisfied (i.e., \(\mathcal{A} \models \Phi\)). In practice, DPLL accomplishes this by selecting a literal \(\ell\), assigning a truth value to it (thus extending \(\mathcal{A}\)), and then simplifying \(\Phi\) accordingly. Then, the simplified formula is checked for satisfiability, and if no conflict arises, the algorithm continues recursively. If a contradiction occurs, DPLL backtracks and tries the opposite assignment for \(\ell\). This process continues until either \(\Phi\) is deemed satisfiable under \(\mathcal{A}\), or the search has been exhausted and \(\Phi\) is deemed unsatisfiable.


