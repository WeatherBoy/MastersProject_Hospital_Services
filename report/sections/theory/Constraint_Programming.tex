\subsection{Constraint Programming}
Another approach for solving the \textit{scheduling task} is Constraint Programming (CP)\footnote{Constraint Programming is a somewhat odd nomenclature, as \textit{programming} here refers to 'the process of scheduling' rather than in the sense of a computer programming language.}. CP is concerned with problems that require a feasible solution. Often, this involves searching for a "needle within a haystack", as CP aims to arrive at a solution satisfying a complex set of constraints. As such, contrary to the GA scheme, CP isn't inherently an optimisation technique and won't even necessarily use an objective function.
\\
As we will argue later, the domain posed by the \textit{scheduling task} gives way to a subdomain of CP called \textit{the Boolean Satisfiability Problem} (SAT). The Boolean Satisfiability Problem concerns checking whether a boolean formula holds (is satisfiable) under some truth assignment to its variables. From the Cook-Levin theorem, produced independently by Stephen Cook\cite{cook-bool-SAT} and Leonid Levin\cite{Levin-bool-SAT}, we know that SAT is NP-complete. This means that there exist no polynomial time algorithm\footnote{As of the time of writing \textit{P versus NP}\cite{Wiki-P-vs-NP} remains unsolved.}, which can solve the \textit{scheduling task}. However, SAT solvers are explicitly made for solving such problems, so in the following sections, we will elaborate on different algorithms employed by such solvers.

\subsubsection{Conjunctive Normal Form}\label{sec:CNF}
However, although not inherent to boolean satisfiability, most SAT solvers work on boolean formulas in Conjunctive Normal Form (CNF). Therefore, we will first introduce CNF.
\\
From Ben-Ari (chapter 4)~\cite{Math-Logic-for-CompSci} we have the following definition:
\begin{definition}\label{def:CNF}
    A formula is in conjunctive normal form (CNF) if and only if it is a conjunction of disjunctions of literals.
\end{definition}
Here, conjunction and disjunction refer to the logical connectives (boolean operators) $\wedge$ and $\vee$, respectively. While a formula and a literal, as given by Ben-Ari (chapter 2)~\cite{Math-Logic-for-CompSci}, can be formally defined as:
\begin{definition}\label{def:propositional_formulas}
    A formula in propositional logic is a tree defined recursively:
    \begin{itemize}
        \item A formula is a leaf labeled by an atomic proposition (often shortened
        to atoms).
        \item A formula is a node labeled by $\neg$ with a single child that is a formula.
        \item A formula is a node labeled by one of the boolean operators with two children both of which are formulas.
    \end{itemize}
\end{definition}
\begin{definition}\label{def:propositional_atoms}
    A literal is an atom or the negation of an atom. An atom is a positive
    literal and the negation of an atom is a negative literal. For any atom $p$, $\{p,\neg p\}$ is a complementary pair of literals.
    \\
    For any formula $A$, $\{A,\neg A\}$ is a complementary pair of formulas. $A$ is the complement of $\neg A$ and $\neg A$ is the complement of $A$.
\end{definition}
We will now briefly discuss how to arrive at CNF.

\paragraph{Propositional logic to Conjunctive Normal Form}
Ben-Ari (chapter 4)~\cite{Math-Logic-for-CompSci} gives us the following theorem:
\begin{theorem}\label{thm:CNF_conversion}
    Every formula in propositional logic can be transformed into an equivalent formula in CNF.
\end{theorem}
Which is accompanied by a somewhat unintuitive and seemingly inadequate proof; however, it can be boiled down to the following: using \textbf{def} \ref{def:propositional_formulas}, if we can convert every formula of another boolean operator into a logically equivalent formula using only conjunctions and disjunctions, then it is simply a question of propagating negations inwards and whether we can redistribute the conjunctions and disjunctions. We can understand this as: It is necessary but not satisfactory that all boolean operators are either disjunctions or conjunctions. This is an example of a formula, for $A$, $B$ being atoms as per \textbf{def} \ref{def:propositional_atoms}, of only conjunctions and disjunctions which aren't in CNF
\begin{equation*}
    A \vee (B \wedge C).
\end{equation*}
And as per the final part of \textbf{def} \ref{def:CNF}, the negation boolean operator must apply solely to an atom, making it a literal. Hence, it is necessary to propagate negations inwards (to the atomic level).
\begin{enumerate}
    \item Converting all boolean operators to disjunctions and conjunctions by logical equivalent\footnote{We will let the reader verify for themselves, that these are in fact equivalent.} formulas:
    \begin{align*}
        A \leftrightarrow B &\equiv (A \rightarrow  B) \wedge (B \rightarrow A) \qquad &\text{biimplication},
        \\
        A \oplus B &\equiv \neg (A \rightarrow B) \vee \neg (B \rightarrow A) \qquad &\text{exclusive or/ logical XOR},
        \\
        A \rightarrow B &\equiv \neg A \vee B \qquad &\text{implication},
        \\
        A \uparrow B &\equiv \neg (A \wedge B) \qquad &\text{non-conjunction/ logical NAND},
        \\
        A \downarrow B &\equiv \neg (A \vee B) \qquad &\text{non-disjunction/ logical NOR}.
    \end{align*}
    \item Propagate negations inward with De Morgan's laws\cite{A-Concise-Introduction-to-Logic,Introduction-to-logic,Math-Logic-for-CompSci}:
    \begin{align*}
        \neg (A \wedge B) &\equiv (\neg A \vee \neg B),
        \\
        \neg (A \vee B) &\equiv (\neg A \wedge \neg B).
    \end{align*}
    \item Remove any redundant double negations, which may arise from the previous two steps:
    \begin{equation*}
        \neg \neg A \equiv A.
    \end{equation*}
    \item Finally, we can make the formula a conjunction of disjunctions by utilising the distributive property of boolean operators:
    \begin{align*}
        A \vee (B \wedge C) &\equiv (A \vee B) \wedge (A \vee C),
        \\
        (A \wedge B) \vee C &\equiv (A \vee C) \wedge (B \vee C) \tag*{\(\blacksquare\).}
    \end{align*}
\end{enumerate}

\subsubsection{Clausal Form}
Before moving on to SAT solvers, we will give a brief yet necessary remark on the Clausal Form.
\\
Ben-Ari (chapter 4)~\cite{Math-Logic-for-CompSci} provides the following definition:
\begin{definition}
    Clausal Form adheres to the following rules:
    \begin{itemize}
        \item A \emph{clause} is a set of literals.
        \item A clause is considered to be an implicit disjunction of its literals.
        \item A \emph{unit clause} is a clause consisting of exactly one literal.
        \item The empty set of literals is the \emph{empty clause}, denoted by \(\square\).
        \item A formula is considered to be an implicit conjunction of its clauses.
        \item The formula that is the \emph{empty set of clauses} is denoted by \(\emptyset\).
    \end{itemize}
\end{definition}
Clausal Form is largely just a notational variant of CNF. However, the significant difference is that Clausal Form is defined in terms of sets, while the standard formula definition came from a recursion using trees, \textbf{def} \ref{def:propositional_formulas}. This property eliminates the possibility of duplicate literals in Clausal Form; nevertheless, it remains logically equivalent.
\\
For completeness, Ben-Ari (chapter 4)~\cite{Math-Logic-for-CompSci} gives the following corollary:
\begin{corollary}
    Every formula \(\Phi\) in propositional logic can be transformed into a logically equivalent formula in Clausal Form.
\end{corollary}
Once more, the accompanying proof is somewhat unclear. However, we will show the equivalence regardless. From \textbf{thm} \ref{thm:CNF_conversion}, we have that any formula \(\Phi\) can be transformed into a logically equivalent formula \(\Phi'\) in CNF, which takes the form
\begin{equation*}
    \Phi' = \bigwedge_{i=1}^m \bigg(
        \bigvee_{j=1}^{n_i} l_{i,j},
    \bigg)
\end{equation*}
where each \(l_{i,j}\) is a literal.
\\
Then, to move from CNF to Clausal Form, we replace each disjunction \( (l_{i,1} \vee \ldots \vee l_{i,n_i}) \) with the \emph{set} of those literals \(\{l_{i,1}, \ldots, l_{i,n_i}\}\). Then we collect all these sets into a single \emph{set of clauses}
\begin{equation*}
    \Delta = \bigg\{
        \{l_{1,1}, \ldots, l_{1,n_1}\}, \ldots, \{l_{m,1}, \ldots, l_{m,n_m}\}
    \bigg\}.
\end{equation*}
By definition, this is a formula in Clausal Form (a set of clauses, each being a set of literals). Conjunction becomes the implicit “and” among these clauses, while disjunction becomes the implicit “or” within each clause.
\\
Now, we eliminate any duplicate litterals within a clause and any cuplicate clauses. This preserves logical equivalence, due to the idempotence property of disjunctions and conjunctions, i.e. \(l \vee l \equiv l\) and \(l \wedge l \equiv l\).
\\
Hence taking a conjunction of disjunctions and “collapsing” it into a set-of-sets does not alter which valuations satisfy the formula. We can then state
\begin{equation}\label{eq:CNF_to_Clausal}
    \Phi' \equiv \Delta.
\end{equation}
And finally, from \autoref{eq:CNF_to_Clausal} and \textbf{thm} \ref{thm:CNF_conversion}, we have that
\begin{equation*}
    \Phi \equiv \Phi' \equiv \Delta \tag*{\(\blacksquare\).}
\end{equation*}

\paragraph{Trivial Clauses} are a final way to simplify Clausal Form. From Ben-Ari (chapter 4)~\cite{Math-Logic-for-CompSci}, we have:
\begin{definition}
    A clause is \emph{trivial} if it contains a pair of clashing literals, i.e. the same atom but with opposite polarity (e.g. \( l \vee \neg l \) ).
\end{definition}
We will, without much proof, simply conclude that if a clause contains a pair of clashing literals, then the clause is trivially true\footnote{Anything, without a shadow of a doubt, most certainly either \emph{is} or \emph{isn't}... aside maybe from quantum, yet that is neither here nor there.} and can be removed from the set of clauses, without altering the truth value of the entire formula.
\\
\\
In appendix \autoref{sec:CNF_conversion_Examp} and \autoref{sec:CNF_to_Clausal_Examp}, we give an example of CNF and Clausal Form conversion, going from
\begin{equation}\label{eq:propositional_logic_example}
    \Big(
        p_1 \leftrightarrow (
            p_2 \vee \neg p_3
        )
    \Big) \wedge \Big(
        p_5 \rightarrow (
            p_1 \uparrow p_4
        )
    \Big) \wedge \Big(
        p_4 \oplus p_2
    \Big),
\end{equation}
to,
\begin{equation*}
    (
        \neg p_1 \vee p_2 \vee \neg p_3
    ) \wedge (
        p_1 \vee \neg p_2 
    ) \wedge (
        p_1 \vee p_3
    ) \wedge (
        \neg p_5 \vee \neg p_1 \vee \neg p_4
    ) \wedge (
        p_2 \vee p_4
    ) \wedge (
        p_2 \vee \neg p_2
    ) \wedge (
        p_4 \vee \neg p_4
    ) \wedge (
        \neg p_2 \vee \neg p_4
    )
\end{equation*}
all the way, to
\begin{equation}\label{eq:clausal_form_example}
    \Big\{
        \{
            \neg p_1, p_2, \neg p_3
        \},
        \{
            p_1, \neg p_2
        \},
        \{
            p_1, p_3
        \},
        \{
            \neg p_5, \neg p_1, \neg p_4
        \},
        \{
            p_2, p_4
        \},
        \{
            \neg p_2, \neg p_4
        \}
    \Big\}.
\end{equation}

\subsubsection{DPLL}
The DPLL algorithm, introduced by Davis, Logemann, and Loveland in 1961~\cite{Original-DPLL-Article}, is a refinement over Davis' and Putnam's (DP) algorithm~\cite{Original-DP-Article} from the year prior. Many modern SAT solvers build off the foundation laid by the DPLL algorithm; as such, it makes for a good introduction.
\\
\\
Conceptually, DPLL inherits from the backtracking paradigm~\cite{Wiki-backtracking}. Like other backtracking algorithms, it aims to avoid exhaustive search by immediately abandoning  'candidate solutions' that do not yield a feasible solution. However, unlike naive backtracking, DPLL includes additional deduction mechanisms, most notably \emph{unit propagation} and \emph{pure literal elimination}, that prune the search space more aggressively.
\\
As previously mentioned, the SAT problem, at its base, concerns checking whether there exists a truth assignment (valuation) \(\mathcal{A}\) such that a given Boolean formula \(\Phi\), expressed in CNF, is satisfied (i.e., \(\mathcal{A} \models \Phi\)). In practice, DPLL accomplishes this by selecting a literal \(\ell\), assigning a truth value to it (thus extending \(\mathcal{A}\)), and then simplifying \(\Phi\) accordingly. Then, the simplified formula is checked for satisfiability, and if no conflict arises, the algorithm continues recursively. If a contradiction occurs, DPLL backtracks and tries the opposite assignment for \(\ell\). This process continues until either \(\Phi\) is deemed satisfiable under \(\mathcal{A}\), or the search has been exhausted and \(\Phi\) is deemed unsatisfiable.
\\
Then there are the deduction mechanisms, enhancing DPLL over basic backtracking, which takes the form of the following rules applied continuously while running the algorithm.

\paragraph{Unit Propagation} is a rule for \emph{Unit Clauses}. Unit Clauses are the case, where a clause contains onley a single literal, \(\{l\}\). Thus \(\Phi\) can only be satisfied, if that literal is assigned its necessary truth value. DPLL starts by appending all the truth values adhering to a Unit Clause to \(\mathcal{A}\). Although Unit Propagation might seem like an obvious approach, it is nevertheless vastly superior to naive backtracking and has the potential to severely trim the search space without negatively impacting runtime.

\paragraph{Pure Literal Elimination} is a rule for atoms which occur in \(\Phi\) with only one polarity. Such an atom \(l^{*}\) is called a \emph{Pure Literal}, and since it occurs as only negative or positive, assigning it the proper truth value will make every clause, \(l^{*}\) occurs in, true. Although it might not be as obvious as Unit Propagation, Pure Literal Eliminations is also a quick and straightforward rule for narrowing down the search space.
\\
\\
Despite the DPLL algorithm's clever application of deduction mechanics, it is still inherently a backtracking algorithm. As such, it retains a running time of \(O(2^n)\), where \(n\) is the number of atoms in \(\Phi\). This, however, is to be expected for an NP-complete problem.
\\
\\
In listing \ref{lst:DPLL}, we present our interpretation of pseudocode for the DPLL algorithm. We have taken a slight liberty in that the pseudocode returns a boolean. This was done to allow for a recursive call on \texttt{DPLL}, evoking the backtracking with a \emph{short-circuiting operator} in the \texttt{return} statement. Additionally, this also serves to keep the pseudocode concise. However, one could imagine an alternate approach where we would be interested in the truth assignment \(\mathcal{A}\). We elected to simply regard this as an implementation detail.

\begin{lstlisting}[caption={DPLL Algorithm (Pseudocode)}, escapeinside={(*}{*)}, label={lst:DPLL}]
    def DPLL((*\(\Phi\)*), (*\(\mathcal{A}\)*)):
        Input: (*A formula \(\Phi\) in Clausal Form and a truth assignment \(\mathcal{A}\)*)
        Output: (*A truth value indicating whether \(\Phi\) is satisfiable*)

        # Unit propagation
        while (*there is a unit clause \(\{l\}\)*) in (*\(\Phi \mid_{\mathcal{A}}\)*):
            (*\(\mathcal{A}\)*) (*\(\leftarrow\)*) unit_propagation((*\(\{l\}\)*), (*\(\mathcal{A}\)*))

        # Pure literal elimination
        while (*there is a pure literal \(l\)*) in (*\(\Phi \mid_{\mathcal{A}}\)*):
            (*\(\mathcal{A}\)*) (*\(\leftarrow\)*) pure_literal_elimination((*\(l\)*), (*\(\mathcal{A}\)*))

        # Stopping conditions
        if (*\(\Phi \mid_{\mathcal{A}}\)*) is empty:
            return True
        if (*\(\Phi \mid_{\mathcal{A}}\)*) contains (*\(\square\)*):
            return False

        # DPLL recursion
        (*\(l\)*) (*\(\leftarrow\)*) choose_literal((*\(\Phi\)*), (*\(\mathcal{A}\)*))
        return DPLL((*\(\Phi\)*), (*\(\mathcal{A} \cup \{l\}\)*)) or DPLL((*\(\Phi\)*), (*\(\mathcal{A} \cup \{\neg l\}\)*))
\end{lstlisting}

\subsubsection{DPLL: Toy example}
Sometimes, the best way to understand an algorithm is just to see it in action. So, we will now run DPLL on \autoref{eq:clausal_form_example}. The first thing to note is that we can't initially use Unit Propagation on \autoref{eq:clausal_form_example}. This is largely due to it being a small example, and although we could artificially add the conjunction "\(\wedge p_4\)" to the original \autoref{eq:propositional_logic_example} without altering the satisfiability, we still see Unit Propagation throughout the example.
\begin{figure}[H]
    \centering
    \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/Constraint-Programming/DPLL-Toy-Example1.png}
        \subcaption*{Step 0: Initially, no literals has been assigned any values.}
    \end{subfigure}
    \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/Constraint-Programming/DPLL-Toy-Example2.png}
        \subcaption*{Step 1: We start with Pure Literal Elimination on \(p_5\) making the 4th clause true.}
    \end{subfigure}
\end{figure}

\begin{figure}[H]
    \centering
    \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/Constraint-Programming/DPLL-Toy-Example3.png}
        \subcaption*{Step 2: Then we assign \texttt{False} to \(p_4\) at random.}
    \end{subfigure}
    \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/Constraint-Programming/DPLL-Toy-Example4.png}
        \subcaption*{Step 3: Assigning \(p_4\) made the 5th clause a unit clause. Therefore we do Unit Propagation on \(p_2\) assigning it \texttt{True}.}
    \end{subfigure}
\end{figure}

\begin{figure}[H]
    \centering
    \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/Constraint-Programming/DPLL-Toy-Example5.png}
        \subcaption*{Step 4: Next, when we try to assign \texttt{False} to \(p_2\), we get a conflict.}
    \end{subfigure}
    \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/Constraint-Programming/DPLL-Toy-Example6.png}
        \subcaption*{Step 5: We backtrack and try \texttt{True} for \(p_2\).}
    \end{subfigure}
\end{figure}
\begin{figure}[H]
    \centering
    \begin{subfigure}[t]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/Constraint-Programming/DPLL-Toy-Example7.png}
        \subcaption*{Step 6: Finally, when we assign \texttt{True} to \(p_1\), we have the satisfying assignment: \(\mathcal{A} = \{p_1 = \text{\texttt{True}}, p_2 = \text{\texttt{True}}, p_3 = \text{\texttt{True}}, p_4 = \text{\texttt{False}}, p_5 = \text{\texttt{False}}\}\).}
    \end{subfigure}
\end{figure}

\subsubsection{Conflict Driven Clause Learning (CDCL)}
\paragraph{Resolution}